## 微调技巧
不做介绍，建议打印以下论文进行食用，加粗的技巧我用过，确实能够提升模型表现。

1. Universal language model fine-tuning for text classification (ACL 2018)
	- Discriminative finetuning（因材施教式微调）：不同层捕获不同的信息类型，应该使用不同的学习率进行微调，$\eta^{l-1} = \eta^l / 2.6$。
	- **Slanted triangular learning rate（STLR）**：斜三角学习率，修改自三角学习率。*公示过于复杂，略。*
	- Gradual unfreezing：一层一层地解冻。
2. An Embarrassingly Simple Approach for Transfer Learning from Pretrained Language Models (NAACL 2019)
	- auxiliary loss：首先预训练语言模型，然后在微调时加入语言模型损失（LM loss）作为辅助损失，即 $L = L_{task} + \gamma L_{LM}$。作者认为这可以避免灾难性遗忘（catastrophic forgetting），并假设语言模型优化目标扮演正则化器的角色，其防止丢失最通用的特征；（*猜测：MLM 之类的优化目标也是可行的*）
	- Sequential Unfreezing：先微调下游任务结构 $n-1$ 个 epoch，然后解冻预训练模型参数再微调 $k-1$ 个 epoch，最后解冻词向量参数，继续微调。使用grid search 获取 n 和 k；（*感觉与 5 类似*）
3. To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks (ACL 2019)
	- ELMo 更适合 feature-based；BERT 更适合 fine-tuning；
	- BERT 的 self-attention 机制更适合 sentence pair tasks，当 ELMo 加上 bi-attention 之后，性能有较大提升；
	- 对于 fine-tuning，在 PTM 上加更多的参数（下游结构）反而有害；对于 feature-based，在 PTM 上~有益；
	- 最初 fine-tuning *ELMo* 更困难，需要更小心地微调超参。一旦微调完成一项任务，其他任务的超参数都与之类似。slanted triangular lr 和 discriminative fine-tuning 对 ELMo 有效，有一些例子还用 gradual unfreezing；
	- 源域和目标域之间的差距对于 adaptation（包括 fine-tuning 和 feature-based）似乎没太大影响。
4. How to fine-tune bert for text classification? (CCL 2019)
	- 如何处理大于 512 的序列；选取哪一层的特征；不同层使用不同的 lr；
	- Within-Task Further Pretraining；In-Domian Further Pretraining；Cross-Domain Further Pretraining；
	- Multi-task Fine-tuning；Few-shot Learning；Further Pretaining on BERT Large。
5. To tune or not to tune? how about the best of both worlds? (CoRR 2019)
	- 分为两步，首先冻结 PTM 参数，学习下游任务结构的参数；然后解冻 PTM 并微调二者。其中两步的学习率不同，第二步的学习率略小于第一步的

## 参数初始化
1. [LSTM 使用 orthogonal_ 初始化](https://www.zhihu.com/question/57828011)，[forget gate bias 初始化为 1](https://www.zhihu.com/question/41631631)[@jozefowicz2015empirical]
2. [Embedding 使用 uniform 初始化](https://www.zhihu.com/question/25097993)
3. [relu使用 kaiming(He) 初始化](https://zhuanlan.zhihu.com/p/75938932)
4. [tanh 初始化推荐使用 Glorot normal](https://www.zhihu.com/question/25097993)

## 激活函数
### 如何选择激活函数？
[如何理解 ReLU activation function?](https://www.zhihu.com/question/59031444)

#### Sigmoid

##### 分类问题为什么用CE，而不是MSE
如下分别为两个损失函数的数学形式。感觉这个问题可能有点被过分解读了，下面总结一下再网上看到的观点。
$$
\begin{aligned}
MSE = & \sum_i(y_i - \hat{y}_i)^2 \\
CE = & - \sum_i y_i \cdot log(\hat{y}_i)
\end{aligned}
$$

- 从模型实际需求的角度
	+ MSE 关注所有类别之间的误差。类别标签虽然是 0,1,2,3... 之类的表示，但是最终都会转为 one-hot 表示。而 MSE 对真实值和预测值之间误差的计算方式是减法，所以 MSE 会关注所有类别的误差。
	+ 与 MSE 不同，CE 只关注正确类别的误差。由于其是乘法，所以所有的错误类别的误差都变成了 0。
- 从误差上限的角度
	+ MSE 的误差有上限，因为只是 $y - \hat{y}$。
	+ 而 CE 的计算方式是 $- y \cdot log(\hat{y})$，由于 $\hat{y} \in [0, 1]$，则 CE 的值域为 $[0, +\inf]$
- 从直觉上
	+ 分类问题的标签没有空间的概念，标签 1 和标签 10 并不是说它们的差距就比标签 1 和标签 2 差距大，而 MSE 就是专门用来衡量距离的。
- 从优化的角度
	+ 貌似有人说 MSE 容易导致梯度消失，主要的原因是 Sigmoid 的导数。然而我感觉不又寸。。。MSE 和 CE 的导数就差了这一项而已，这能有多大区别。。。

参考：
1. [为什么平方损失函数不适用分类问题？](https://www.zhihu.com/question/319865092/answer/717476767)
2. [MSE vs 交叉熵](https://zhuanlan.zhihu.com/p/84431551)

#### ReLU家族
ReLU 的函数是 $a = max(0, x)$，同时它还拥有许多变体。但是如下图所示，总的来说，它就分为两类。一类是负域线性，另一类是负域非线性。
![几种常见的激活函数](https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/如何选择激活值？/几种常见的激活函数.jpg)

如果你期望某个张量在不断地被计算的过程中，最后输出越小越好（接近 0），那么最好别使用 ReLU。

例如，我碰到了一个问题。我参考论文《[Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory](https://arxiv.org/pdf/1704.01074.pdf)》设计了一个模块，简单来说就是有一个 memory，它会在神经网络计算过程中参与运算（加减操作），当一个批次计算完毕时，我们期望这个 memory 会被释放至 0（*越接近越好*）。然后我在制作这个模块时使用了 relu 函数，我发现我的神经网络将它的权重调整的很奇怪。在进入 relu 函数之前，$x \cdot W$ 总是输出负数。我的分析是：由于 relu 函数的负域总是输出 0，而我们的要求是在处理完一个批次后，memory 需要释放至 0，所以这个模块索性就让它永远等于 0，而不会在计算过程中既有产生 memory，又有释放 memory。因为让输出 0 是一件很简单的事，神经网络只需要学习让线性变换的输出全部为负数即可。

为了让神经网络不那么简单就学习到我们的要求，即不要让它总是输出 0，而是希望它能有加有减，所以我使用 elu 替代了它。

### 为什么Tanh收敛速度比Sigmoid快？
首先看如下两个函数的求导：
$$
\begin{aligned}
	tanh^{\prime}(x) = & 1-tanh(x)^{2}\in (0,1) \\
	s^{\prime}(x) = & s(x)*(1-s(x))\in (0,\frac{1}{4}]
\end{aligned}
$$

由上面两个公式可知tanh(x)梯度消失的问题比sigmoid轻，所以Tanh收敛速度比Sigmoid快。tanh 梯度消失的问题要轻，自然而然参数更新的速度就要快，所以收敛的速度就要快。

## dropout
1. **为什么要正则化？**
深度学习可能存在过拟合问题——高方差，有两个解决方法，一个是正则化，另一个是准备更多的数据，这是非常可靠的方法，但你可能无法时时刻刻准备足够多的训练数据或者获取更多数据的成本很高，但正则化通常有助于避免过拟合或减少你的网络误差。  
2. **为什么正则化有利于预防过拟合？**
3. **理解dropout正则化**：Dropout可以随机删除网络中的神经单元，它为什么可以通过正则化发挥如此大的作用呢？
​	- 直观上理解：不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，dropout将产生收缩权重的平方范数的效果，和之前讲的L2正则化类似；实施dropout的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；L2对不同权重的衰减是不同的，它取决于激活函数倍增的大小。
	- 起平均作用：在不适用 dropout 的条件下，使用 5 个不同的神经网络去训练相同的数据集，那么我们可以使用少数服从多数的方法。比如 3 个神经网络的结果是 b，2 个神经网络的结果是 a，那么结果就是 b。同理，使用 dropout 就相当于训练了不同的神经网络。
4. **dropout率的选择**
5. **dropout有什么缺点？**：dropout一大缺点就是代价函数J不再被明确定义，每次迭代，都会随机移除一些结点，如果再三检查梯度下降的性能，实际上是很难进行复查的。所以我们失去了调试工具来绘制这样的图片。

## 预训练与微调(fine tuning)
1. **为什么无监督预训练可以帮助深度学习？**
	- 深度网络存在问题:
		1. 网络越深，需要的训练样本数越多。若用监督则需大量标注样本，不然小规模样本容易造成过拟合。深层网络特征比较多，会出现的多特征问题主要有多样本问题、规则化问题、特征选择问题。
		2. 多层神经网络参数优化是个高阶非凸优化问题，经常得到收敛较差的局部解；
		3. 梯度扩散问题，BP算法计算出的梯度随着深度向前而显著下降，导致前面网络参数贡献很小，更新速度慢。
	- 解决方法：逐层贪婪训练，无监督预训练（unsupervised pre-training）即训练网络的第一个隐藏层，再训练第二个…最后用这些训练好的网络参数值作为整体网络参数的初始值。经过预训练最终能得到比较好的局部最优解。
4. **fine-tuning 模型的三种状态**
	1. 状态一：只预测，不训练。
   特点：相对快、简单，针对那些已经训练好，现在要实际对未知数据进行标注的项目，非常高效；
	2. 状态二：训练，但只训练最后分类层。
   特点：fine-tuning的模型最终的分类以及符合要求，现在只是在他们的基础上进行类别降维。
	3. 状态三：完全训练，分类层+之前卷积层都训练
   特点：跟状态二的差异很小，当然状态三比较耗时和需要训练GPU资源，不过非常适合fine-tuning到自己想要的模型里面，预测精度相比状态二也提高不少。

## 如何缓解过拟合
注意：处理过拟合，一定是模型已经调参调的差不多了才用，调参的时候可以不用。[有了提前中止防止过拟合方法为什么还需要 L1,L2,dropout 防止过拟合的方法？](https://www.zhihu.com/question/360181480/answer/936386049)

### 正则化
1. weight decay
2. layer norm：将 norm 加在输出上，即输出后立马加上
3. [dropout：加在输出层之前的那层就行了](https://www.zhihu.com/question/41631631)
4. label smoothing

## 如何继续收敛
请注意，learning rate decay 并不是处理过拟合的手段，相反，它会使得模型越来越过拟合。因为学习率衰减本质是让模型在训练集上放慢脚步继续进一步拟合。

1. learning rate decay：其中 step = 1 就是 exponential；step 只能以固定的步长进行衰减，multi-step 可以控制每步的步长。一般用 step 就行了。
	1. **step**
	2. multi-step
	3. exponential
	4. cosine annealing with warm restart
	5. warm up

## 玄学
```
while True:
    rand_seed = random.randint(0, 99999)
    torch.manul_seed(rand_seed)
    save(rand_seed)
    run_model()
    # 然后去玩几天游戏
```

## 📚参考文献
- dropout
	1. [深度学习中Dropout原理解析](https://zhuanlan.zhihu.com/p/38200980)

