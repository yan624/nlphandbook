å†™ä¸‹æ­¤æ–‡ç« æ—¶ï¼Œè· Transformer å‘è¡¨å·²è¿‡å» 3 å¹´ï¼Œç½‘ç»œä¸Šæ—©å·²ç»å……æ–¥ç€å„ç§è®²è§£ï¼Œæ‰€ä»¥æœ¬æ–‡ä¸æ‰“ç®—é‡å¤è¿™äº›å·¥ä½œã€‚å¯¹ Transformer ç»“æ„çš„è®²è§£å¯å‚è€ƒ[ã€Šå¯è§†åŒ–ç†è§£Transformerç»“æ„ã€‹](https://zhuanlan.zhihu.com/p/59629215)ï¼Œæˆ–è€…è‹±æ–‡ç‰ˆ [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)ã€‚ä»¥ä¸‹åªç®€å•åœ°ä»‹ç» Transformer å„é¡¹ç»“æ„çš„è®¡ç®—å…¬å¼ã€‚

å°†å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆMulti-Head Attentionï¼‰è®°ä½œ MHAï¼Œå°†å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆForward-Feed Networkï¼‰è®°ä½œ FFNã€‚

## Transformeré€šç”¨ç»“æ„

å°† Transformer æ¨¡å‹å®šä¹‰ä¸ºå‡½æ•° $y = F(x)$ï¼Œå…¶ä¸­ $y$ æ˜¯ Transformer é¡¶å±‚çš„è¾“å‡ºï¼Œ$x$ æ˜¯åº•å±‚çš„è¾“å…¥ã€‚$F(x)$ å°†é‡å¤è°ƒç”¨ä¸€ä¸ªæ¨¡å—ï¼ˆç§°ä¸º Transformer layerï¼‰ N æ¬¡ï¼Œè¯¥æ¨¡å—åˆç”± B ä¸ªï¼ˆ2æˆ–3ä¸ªï¼‰Transformer Block ç»„æˆã€‚Transformer Block å¯ä»¥è¡¨ç¤ºä¸ºï¼š

$$
a^l_i = f(x) = \text{LayerNorm}^l_i(a^{l-1}_i + \text{sublayer}^l_i(a^{l-1}_i))
$$

å…¶ä¸­ $l$ ä»£è¡¨å±‚æ•°ï¼Œ$i$ ä»£è¡¨ç¬¬ $l$ å±‚çš„ç¬¬ $i$ ä¸ªå­å±‚ã€‚

æ— è®ºæ˜¯ Transformer encoder è¿˜æ˜¯ Transformer decoderï¼Œå…¶è®¡ç®—æµç¨‹ä¸ºï¼š

```
for l in range(N):
	for i in range(B):
		f(x)
```

ä» Transformer ç»“æ„æ¥è¯´ï¼Œ$f(x)$ çš„è®¡ç®—æµç¨‹æ˜¯ï¼šè¾“å…¥åºåˆ— $x$ å…ˆè¿›å…¥å­å±‚ï¼ˆMHA æˆ– FFNï¼‰ï¼Œç„¶åå°†è¾“å‡ºä¸ $x$ ç›¸åŠ ï¼Œå³æ®‹å·®ç½‘ç»œï¼Œæœ€åå°†ç»“æœè¾“å…¥å±‚æ ‡å‡†åŒ–ï¼ˆlayer normalizationï¼‰ä¸­ã€‚ä»¥æ­¤ç±»æ¨å®Œæˆä¸€å±‚çš„è®¡ç®—ã€‚

æœ‰ä»¥ä¸‹å‡ ç‚¹éœ€è¦è¯´æ˜ï¼š1ï¼‰è¾“å…¥è¯å‘é‡ï¼›2ï¼‰MHA å’Œ FNN çš„è®¡ç®—å…¬å¼åˆ†åˆ«æ˜¯ä»€ä¹ˆã€‚

**è¾“å…¥è¯å‘é‡**æ˜¯

$$X = E_{token} + E_{pos} + E_{seg}
$$

?> ç”±äº Transformer ä¸åŒ…å«å¾ªç¯å’Œå·ç§¯ï¼Œå› æ­¤ä¸ºäº†ä½¿æ¨¡å‹åˆ©ç”¨åºåˆ—é¡ºåºï¼Œå¿…é¡»æ³¨å…¥ç¬¦å·ç›¸å¯¹æˆ–ç»å¯¹çš„ä½ç½®ä¿¡æ¯ã€‚ä¸ºæ­¤ï¼Œencoder å’Œ decoder åº•å±‚çš„è¾“å…¥åµŒå…¥è¢«åŠ ä¸Šäº†â€œä½ç½®ç¼–ç â€ã€‚æœ‰è®¸å¤šå­¦å¥½çš„æˆ–è€…å›ºå®šçš„ä½ç½®ç¼–ç å¯ä¾›é€‰æ‹©[[@gehring2017convolutional]](#gehring2017convolutional)ã€‚è®ºæ–‡å¯¹æ¯”ä¸¤ç§ç±»åˆ«çš„ä½ç½®ç¼–ç ä¹‹åï¼Œå‘ç°å®ƒä»¬çš„ç»“æœéå¸¸æ¥è¿‘ã€‚é€‰æ‹©å›ºå®šç¼–ç æ˜¯å› ä¸ºå®ƒå¯ä»¥æ¨ç†åºåˆ—é•¿åº¦ï¼Œä»¥æ­¤è¡¨ç¤ºæ¯”è®­ç»ƒé›†ä¸­å·²çŸ¥æœ€é•¿åºåˆ—æ›´é•¿çš„åºåˆ—ã€‚åœ¨ [get_timing_signal_1d()](https://github.com/tensorflow/tensor2tensor/blob/23bd23b9830059fbc349381b70d9429b5c40a139/tensor2tensor/layers/common_attention.py#L387) å‡½æ•°ä¸­å¯ä»¥çœ‹åˆ°ç”¨äºç”Ÿæˆä½ç½®ç¼–ç çš„ä»£ç ã€‚

**MHA** çš„è®¡ç®—å…¬å¼å¦‚ä¸‹æ‰€ç¤ºï¼Œå…¶ä¸­ $[Q, K, V] = \text{Linear}(X) \in \mathbb{R}^{<d(X)}$ã€‚
$$
\begin{aligned}
	\text{MHA}(X) & = \text{Linear}([Attn_1; \cdots; Attn_8]) \in \mathbb{R}^{d(X)} \\
	\text{Attn}(Q, K, V) & = \text{softmax}(\frac{Q K^T}{\sqrt{d_k}}) V \in \mathbb{R}^{<d(X)} \\
\end{aligned}
$$

**FFN** çš„è®¡ç®—å…¬å¼å¦‚ä¸‹æ‰€ç¤ºï¼Œå…¶ä¸­æ¿€æ´»å‡½æ•°ä¸ä¸€å®šéè¦æ˜¯ $ReLU(x) = max(0, x)$ï¼Œæœ‰äº›è®ºæ–‡è¿˜ä¼šç”¨ $\text{GELU}$ã€‚

$$\text{FNN}(x) = max(0, x \cdot W_1 + b_1) \cdot W_2 + b_2
$$

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œmulti-head attention çœ‹è‹±æ–‡åæ„Ÿè§‰â€œé«˜å¤§ä¸Šâ€ã€‚å…¶å®å¾ˆç®€å•ï¼Œå°±æ˜¯å°† self-attention æ‰§è¡Œå¤šæ¬¡ã€‚Transformer æ‰§è¡Œäº† 8 æ¬¡ï¼Œå› æ­¤äº§ç”Ÿ 8 ä¸ªå‘é‡ã€‚ç„¶è€Œï¼Œåœ¨è®­ç»ƒæ—¶åªéœ€è¦ä¸€ä¸ªå‘é‡ã€‚ä¸ºæ­¤ï¼ŒTransformer æ‹¼æ¥ 8 ä¸ªå‘é‡ï¼Œå†ä¹˜ä¸Šä¸€ä¸ªæƒé‡çŸ©é˜µï¼Œä½¿å…¶ç»´åº¦è¿˜åŸã€‚

## Encoder-Decoder Attention
å¯¹äº Transformer decoder æ¥è¯´ï¼Œç”±äºå®ƒéœ€è¦ä¸ç¼–ç å™¨äº¤äº’ï¼Œå› æ­¤å®ƒè¿˜å¤šäº†ä¸€ä¸ª Encoder-Decoder Attention å­å±‚ï¼Œå…·ä½“åœ¨ MHA å’Œ FFN ä¹‹é—´ã€‚

å…·ä½“æ¥è¯´ï¼ŒEncoder Decoder Attention çš„ QKV è·å–æ–¹å¼ä¸ self-attention ç•¥æœ‰ä¸åŒã€‚Q æ¥è‡ªè¾“å…¥åºåˆ—çš„çº¿æ€§å˜æ¢ï¼Œä½†æ˜¯ KV æ¥è‡ª encoder é¡¶å±‚è¾“å‡ºçš„çº¿æ€§å˜æ¢ã€‚è¿™æœ‰åŠ©äºè§£ç å™¨å°†æ³¨æ„åŠ›é›†ä¸­åœ¨è¾“å…¥åºåˆ—çš„åˆé€‚ä½ç½®ã€‚**åšä¸»æ³¨**ï¼šä»¥ä¸Š QKV çš„ç”¨æ³•æ¥è‡ªå¯¹ pytorch å®˜æ–¹æºç çš„åˆ†æã€‚

## encoderå’Œdecoderä¸­self-attentionçš„åŒºåˆ«
åœ¨ NLP ä¸­ï¼Œè¾“å…¥åˆ°æ¨¡å‹çš„**ä¸€æ‰¹**åºåˆ—å¤§æ¦‚ç‡ä¸ç­‰é•¿ã€‚åœ¨è®­ç»ƒæ—¶éœ€è¦ padding maskï¼Œè®©æ¨¡å‹ä¸è¦æå–å¡«å……å•è¯çš„ä¿¡æ¯ã€‚ä¸è¿‡ï¼ŒTransformer decoder ä¸ºäº†ä¸è®©æ¨¡å‹åœ¨è§£ç æ—¶å…³æ³¨â€œæœªæ¥â€çš„å•è¯ï¼Œè¿˜éœ€è¦ sequence maskã€‚å› æ­¤ encoder å’Œ decoder çš„ self-attention çš„åŒºåˆ«æ˜¯ï¼šdecoder çš„ self-attention æ˜¯ **masked multi-head attention**ï¼Œè€Œ encoder çš„ä»…ä»…æ˜¯ **multi-head attention**ã€‚è¯¦è§ä¸‹é¢ **mask** ä¸€èŠ‚ã€‚

## ğŸ¤¿mask
Transformer decoder çš„ mask æŒ‡çš„æ˜¯ **sequence/padding mask**ï¼Œencoder çš„ mask æŒ‡çš„æ˜¯ **padding mask**ã€‚å¯å‚è€ƒæ–‡çŒ® 3ã€4ã€‚

**padding mask** æ˜¯ä¸ºäº†é˜²æ­¢å¡«å……å€¼ PAD å…·æœ‰æ„ä¹‰ã€‚åœ¨åå‘ä¼ æ’­æ—¶ï¼Œå¦‚æœä¸åš padding maskï¼Œæ¡†æ¶ä¼šå¯¹ PAD æ±‚å¯¼ã€‚ä½†æ˜¯é€šå¸¸ PAD è¢«è®¤ä¸ºæ˜¯ä¸€ä¸ªæ— æ„ä¹‰çš„å¡«å……ç¬¦ï¼Œæ‰€ä»¥æœ€å¥½ä¸è¦è®¡ç®—å…¶æ¢¯åº¦ã€‚**å¯¹äº Transformerï¼Œæ— è®º encoder è¿˜æ˜¯ decoder éƒ½è¦åš mask**ã€‚**sequence mask** æ˜¯ä¸ºäº†é®ä½æ¥è‡ªæœªæ¥çš„ä¿¡æ¯ï¼Œä½¿å¾— decoder åœ¨è§£ç æ—¶ï¼Œä¸ä¼šä¾èµ–æœªæ¥çš„ä¿¡æ¯ã€‚

### padding mask
åœ¨ encoder ä¸­,æ¯æ¬¡æ‰§è¡Œ scaled dot-product åéƒ½è¦åšä¸€æ¬¡ padding maskã€‚ç”±äºæˆ‘ä»¬è¦è®©åºåˆ—çš„é•¿åº¦ç›¸ç­‰ä»¥ä¾¿åšå‘é‡åŒ–æ“ä½œï¼Œæ‰€ä»¥å¿…ä¸å¯å°‘åœ°éœ€è¦å¯¹è¾“å…¥åºåˆ—è¿›è¡Œ**æˆªæ–­**æˆ–**è¡¥é›¶**ï¼ˆå³å¡«å…… PADï¼ŒPAD ä¸ä¸€å®šéè¦æ˜¯ 0ï¼‰æ“ä½œã€‚æ‰€ä»¥ padding mask çš„**ä¸»è¦ç›®çš„**æ˜¯ä½¿å¾— self-attention ä¸è¦å…³æ³¨å‘é‡ä¸­çš„ PAD ç¬¦å·ï¼Œä½¿ç¥ç»ç½‘ç»œå¿½ç•¥ PAD çš„ä¿¡æ¯ã€‚

åœ¨åš attention ä¹‹å‰ï¼Œå…ˆæŠŠ PAD æ‰€åœ¨ä½ç½®çš„å€¼ç½®ä¸ºä¸€ä¸ªæå°å€¼ï¼Œç”šè‡³æ˜¯æ— ç©·å°ï¼ˆç”±äº attention éœ€è¦ç»è¿‡ softmaxï¼Œsoftmax éœ€è¦æ±‚ e çš„æ¬¡æ–¹ï¼Œè¦æƒ³ e çš„æŸæ¬¡æ–¹ä¸º 0ï¼Œåªèƒ½ä½¿å¾—å€¼ä¸ºæ— ç©·å°æ‰å¯ä»¥ï¼Œè¿™æ˜¯ä¸€ä¸ªæ•°å­¦é—®é¢˜ï¼‰ã€‚

mask çš„**å…·ä½“æ“ä½œ**æ˜¯ï¼šåœ¨æ‰§è¡Œ scaled dot-product **å**ï¼Œå°†åºåˆ—ä¸­è¡¥é›¶ä½ç½®æ‰€å¯¹åº”çš„éšè—çŠ¶æ€ç½®ä¸º -INFï¼Œä½¿å¾—åºåˆ—ç»è¿‡ softmax å±‚æ—¶ï¼Œ**è¯¥å¯¹åº”ä½ç½®æ‰€è®¡ç®—å‡ºçš„æ¦‚ç‡ä¸º 0**ã€‚ï¼ˆ*mask æ“ä½œåœ¨ Transformer ä¸­è²Œä¼¼æ˜¯å¯é€‰çš„ã€‚*ï¼‰

?> é™¤äº† Transformerï¼Œå…¶ä»–ç®—æ³•å¯èƒ½ä¹Ÿéœ€è¦ padding maskï¼Œä¸‹é¢åˆ—ä¸¾ Embeddingã€LSTM å’Œ loss è®¡ç®—ä¸‰ç§æƒ…å†µã€‚

1. **å¯¹äº Embedding å±‚**æ¥è¯´ï¼Œç¬¦å· PAD çš„è¯å‘é‡æ˜¯æ— æ„ä¹‰çš„ï¼Œå¯ä»¥ä½¿ç”¨ä¸Šè¿°ç±»ä¼¼çš„æ–¹æ³•ï¼Œä¹˜ä¸€ä¸ª maskã€‚ä¸è¿‡è¿™æ ·ç•¥å¾®éº»çƒ¦ï¼Œæ‰€å¹¸çš„æ˜¯ Pytorch æä¾›äº†ç®€å•çš„å®ç°ï¼Œåªéœ€è¦å¡«å…¥ `padding_idx` å³å¯å®ç°ä¸Šè¿°åŠŸèƒ½ã€‚ä½†æ˜¯è¿™åªæ˜¯è®© PAD è¿™ä¸ªè¯å‘é‡æ— æ„ä¹‰å¹¶ä¸”ä¸è®¡ç®—å®ƒçš„æ¢¯åº¦è€Œå·²ã€‚åœ¨ç»è¿‡å¤æ‚çš„è®¡ç®—ä¹‹å PAD æ‰€åœ¨ä½ç½®çš„å€¼ä¾æ—§ä¼šå˜ä¸ºé 0ã€‚å¯¹äºåµŒå…¥å±‚ä¹‹åçš„éšè—å±‚ï¼Œpytorch æ²¡æœ‰æä¾›è¿™ä¹ˆç®€å•çš„æ–¹å¼ï¼Œéœ€è¦ä¹˜ä¸Šä¸€ä¸ª mask çŸ©é˜µã€‚
```
nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_ID)
```
2. **å¯¹äº LSTM ç­‰çš„æ—¶åºç‰¹å¾æå–å±‚**å¯ä»¥ä½¿ç”¨ `torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=True)` å‡½æ•°å°† embedding æ‰“åŒ…ã€‚ç„¶åå°†è¿™ä¸ªæ‰“åŒ…åçš„ embedding è¾“å…¥ LSTMï¼Œä¹‹åä½¿ç”¨ `torch.nn.utils.rnn.pad_packed_sequence(sequence, batch_first=False, padding_value=0.0, total_length=None)` å‡½æ•°ï¼Œå°† LSTM çš„è¾“å‡ºè¿˜åŸã€‚
ä»¥ä»¥ä¸‹ä»£ç ä¸ºä¾‹ï¼Œå…¶ä¸­ç¬¬ä¸€è¡Œä»£ç çš„ `lengths` å¿…é¡»æ˜¯ pytorch çš„ tensorï¼Œå®ƒä»£è¡¨ç€ä½ è¾“å…¥åºåˆ—çš„é•¿åº¦ï¼Œæ¯”å¦‚ä½ è¾“å…¥ [['ä½ ', 'å¥½', 'ã€‚'], ['æˆ‘', 'æ˜¯', 'é±¼', 'ã€‚']]ï¼Œé‚£ä¹ˆ `lengths` å°±æ˜¯ `torch.Tensor([3, 4])`ã€‚`batch_first` é»˜è®¤æ˜¯ Falseï¼Œè¿™æ˜¯å› ä¸º LSTM çš„è¾“å…¥è¦æ±‚æ˜¯ (S, N, *)ï¼Œå…¶ä¸­ S æ˜¯åºåˆ—é•¿åº¦ï¼ŒN æ˜¯æ‰¹æ¬¡å¤§å°ã€‚`batch_first` é¡¾åæ€ä¹‰å°±æ˜¯è¾“å…¥çš„åºåˆ—çš„ç¬¬ä¸€ä¸ªç»´åº¦æ˜¯å¦ä¸ºæ‰¹æ¬¡å¤§å°ï¼Œæ˜¾ç„¶ä¸ºäº†ä½¿å¾— pytorch å†…éƒ¨å…¼å®¹ï¼Œ`batch_first` é»˜è®¤ä¸º `False` æ˜¯æœ€å¥½çš„ã€‚ä¸€èˆ¬æˆ‘éƒ½æ‡’å¾—å¯¹åºåˆ—è¿›è¡Œé•¿åº¦ä¸Šçš„æ’åºï¼Œæ‰€ä»¥å°† `enforce_sorted` è®¾ç½®ä¸º Falseã€‚
```
# lstm padding mask
packed_feature = nn.utils.rnn.pack_padded_sequence(embed, lengths, enforce_sorted=False)
packed_bi_feature, hx = self.lstm(packed_feature)
bi_feature, lengths_unpacked = nn.utils.rnn.pad_packed_sequence(packed_bi_feature)
```
3. æœ€å**åœ¨è®¡ç®— loss æ—¶**ä¹Ÿéœ€è¦ padding maskï¼Œè¿™å¯ä»¥ä½¿ç”¨ `torch.masked_select(input, mask, out=None)` è¿›è¡Œè®¡ç®—ã€‚

### sequence mask
é€šå¸¸ï¼Œdecoder è¢«ç¦æ­¢çœ‹è§æœªæ¥çš„ä¿¡æ¯ã€‚ä½¿ç”¨ sequence mask å¯ä»¥ä½¿å…¶åªå…³æ³¨å½“å‰æ—¶é—´æ­¥ä¹‹å‰çš„å•è¯ï¼Œè€Œä¸ä½¿ç”¨åé¢æœªè§£ç å‡ºå•è¯çš„ä¿¡æ¯ã€‚

sequence mask çš„ç¤ºä¾‹å¦‚ä¸‹æ‰€ç¤ºã€‚å…¶å® sequence mask å°±æ˜¯ä¸€ä¸ª $L \times L$ ç»´çš„çŸ©é˜µï¼ŒL ä»£è¡¨ä¸€æ¡è¯­å¥çš„é•¿åº¦ã€‚å…¶å†…å®¹æ˜¯ï¼Œä¸‹ä¸‰è§’ä»¥åŠå¯¹è§’çº¿å…¨éƒ¨ä¸º 1ï¼Œä»£è¡¨éœ€è¦è¿™éƒ¨åˆ†ä¿¡æ¯ã€‚ä¸Šä¸‰è§’å…¨éƒ¨ä¸º 0ï¼Œä»£è¡¨è¿™éƒ¨åˆ†ä¿¡æ¯è¢«æ©ç›–ã€‚

```
æˆ‘**
æˆ‘æ˜¯*
æˆ‘æ˜¯é±¼
```

## ğŸ“šå‚è€ƒæ–‡çŒ®
1. [æ”¾å¼ƒå¹»æƒ³ï¼Œå…¨é¢æ‹¥æŠ±Transformerï¼šè‡ªç„¶è¯­è¨€å¤„ç†ä¸‰å¤§ç‰¹å¾æŠ½å–å™¨ï¼ˆCNN/RNN/TFï¼‰æ¯”è¾ƒ](https://zhuanlan.zhihu.com/p/54743941)
2. [ã€ŠBERTå¤§ç«å´ä¸æ‡‚Transformerï¼Ÿè¯»è¿™ä¸€ç¯‡å°±å¤Ÿäº†ã€‹](https://zhuanlan.zhihu.com/p/54356280)
1. [Transformeræ¨¡å‹çš„PyTorchå®ç°](https://luozhouyang.github.io/transformer/)
2. [The Transformer](https://www.jianshu.com/p/405bc8d041e0)
3. [æ·±åº¦å­¦ä¹ ä¸­çš„ mask åˆ°åº•æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ](https://www.zhihu.com/question/320615749/answer/1080485410)
4. [å˜é•¿åºåˆ—æ€ä¹ˆä½¿ç”¨ mini-batch SGD è®­ç»ƒï¼Ÿ](https://www.zhihu.com/question/264501322/answer/433784349)
5. [transformer åœ¨è§£ç çš„æ—¶å€™ï¼Œç”¨çš„ k å’Œ v çš„å‘é‡æ¥è‡ªäºç¼–ç å™¨çš„è¾“å‡ºè¿˜æ˜¯æ¥è‡ªäºä¹‹å‰è§£ç è¾“å‡ºçš„å€¼å‘¢ï¼Ÿ](https://www.zhihu.com/question/347366108/answer/832932755)
6. [ã€è®¡ç®—æœºè§†è§‰ã€å„ç§Normalizationå±‚è¾¨æ](https://www.cnblogs.com/hellcat/p/9735041.html#_label3_0) 
7. [layer normalization ç®€å•æ€»ç»“](https://www.jianshu.com/p/c357c5717a60)

<textarea id="bibtex_input" style="display:none;">
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  pages={5998--6008},
  year={2017}
}
@article{gehring2017convolutional,
  title={Convolutional sequence to sequence learning},
  author={Gehring, Jonas and Auli, Michael and Grangier, David and Yarats, Denis and Dauphin, Yann N},
  journal={arXiv preprint arXiv:1705.03122},
  year={2017}
}
</textarea>
